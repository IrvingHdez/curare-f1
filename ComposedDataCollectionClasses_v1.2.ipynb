{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success class created!\n"
     ]
    }
   ],
   "source": [
    "class DataCollection:\n",
    "    _id = \"\"\n",
    "    name = \"\"\n",
    "    provider = \"\"\n",
    "    licence = \"\"\n",
    "    size = 0\n",
    "    author = \"\"\n",
    "    description = \"\"        \n",
    "    \n",
    "    releaseList = []\n",
    " \n",
    "    def __init__(self, _id, name, provider, licence, size, author, description, releaseList):\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.provider = provider\n",
    "        self.licence = licence\n",
    "        self.size = size\n",
    "        self.author = author\n",
    "        self.description = \"Add API decription\"\n",
    "        \n",
    "        self.releaseList = releaseList\n",
    " \n",
    "    def printInfo(self):\n",
    "        print (\"_id  = \" + self._id)\n",
    "        print (\"name  = \" + self.name)\n",
    "        print (\"provider  = \" + self.provider)\n",
    "        print (\"licence  = \" + self.licence)\n",
    "        print (\"size = \" + str(self.size) + \" Bytes\")\n",
    "        print (\"author  = \" + self.author)\n",
    "        print (\"description  = \" + self.description)\n",
    "        print (\"list of releases = \" + str(self.releaseList))      \n",
    "        \n",
    "print (\"Success class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success class created!\n"
     ]
    }
   ],
   "source": [
    "# Get conditions in which data is produced\n",
    "class Release:\n",
    "    _id = \"\"\n",
    "    releaseNum = 0\n",
    "    publicationDate = \"\"    \n",
    "    \n",
    "    itemList = []\n",
    "    size = 0   # added by me\n",
    "    \n",
    "    def __init__(self, _id, releaseNum, publicationDate, itemList, size):\n",
    "        self._id = _id\n",
    "        self.releaseNum = releaseNum\n",
    "        self.publicationDate = publicationDate        \n",
    "        self.itemList = itemList\n",
    "        self.size = size\n",
    "        \n",
    "    def incRelease(self):\n",
    "        self.releaseNum = self.releaseNum + 1    \n",
    "        \n",
    "    def printInfo(self):\n",
    "        print (\"_id  = \" + self._id)\n",
    "        print (\"releaseNum  = \" + str(self.releaseNum))\n",
    "        print (\"publicationDate  = \" + self.publicationDate)                \n",
    "        print (\"List of items = \" + str(self.itemList))\n",
    "        print (\"size = \" + str(self.size) + \" Bytes\")\n",
    "\n",
    "print (\"Success class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success class created!\n"
     ]
    }
   ],
   "source": [
    "class Item:\n",
    "    _id = \"\"\n",
    "    name = \"\"\n",
    "    content = []\n",
    "    \n",
    "    size = 0   # added by me\n",
    " \n",
    "    def __init__(self, _id, name, content, size):\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "        self.size = size\n",
    "        \n",
    "    def printInfo(self):\n",
    "        print (\"_id  = \" + self._id)\n",
    "        print (\"name  = \" + self.name)\n",
    "        print (\"content  = \" + str(self.content))\n",
    "        print (\"size = \" + str(self.size) + \" Bytes\")\n",
    "\n",
    "print (\"Success class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harvest Data from HTTP and Unarchived it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set has been downloaded, the following files were extracted extracted:\n",
      "/tmp/f1db_csv/pit_stops.csv\n",
      "/tmp/f1db_csv/races.csv\n",
      "/tmp/f1db_csv/lap_times.csv\n",
      "/tmp/f1db_csv/constructors.csv\n",
      "/tmp/f1db_csv/constructor_results.csv\n",
      "/tmp/f1db_csv/status.csv\n",
      "/tmp/f1db_csv/driver.csv\n",
      "/tmp/f1db_csv/seasons.csv\n",
      "/tmp/f1db_csv/driver_standings.csv\n",
      "/tmp/f1db_csv/qualifying.csv\n",
      "/tmp/f1db_csv/constructor_standings.csv\n",
      "/tmp/f1db_csv/circuits.csv\n",
      "/tmp/f1db_csv/results.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "from os import listdir\n",
    "import zipfile\n",
    "\n",
    "url = \"http://ergast.com/downloads/f1db_csv.zip\"\n",
    "tempPath = '/tmp/'\n",
    "file_name = tempPath + \"f1db_csv.zip\"\n",
    "dataFolder = \"f1db_csv/\"\n",
    "\n",
    "# Download the file from 'url' and save it locally under 'file_name':\n",
    "with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)        \n",
    "\n",
    "# Unarchive data\n",
    "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "zip_ref.extractall(tempPath + dataFolder) # creates folder f1db_csv if it doesn't exist\n",
    "zip_ref.close()\n",
    "\n",
    "listFilePath = os.listdir(tempPath + dataFolder)\n",
    "\n",
    "print (\"Data set has been downloaded, the following files were extracted extracted:\")\n",
    "\n",
    "for f in listFilePath:  \n",
    "    fullPath = tempPath + dataFolder + f\n",
    "    print (fullPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create item objects and append them to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = pit_stops.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'int'), ('_c4', 'string'), ('_c5', 'string'), ('_c6', 'int')]\n",
      "size = 254006 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = races.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'int'), ('_c4', 'string'), ('_c5', 'timestamp'), ('_c6', 'string'), ('_c7', 'string')]\n",
      "size = 109577 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = lap_times.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'int'), ('_c4', 'string'), ('_c5', 'int')]\n",
      "size = 12993131 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = constructors.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'string'), ('_c2', 'string'), ('_c3', 'string'), ('_c4', 'string')]\n",
      "size = 17021 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = constructor_results.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'double'), ('_c4', 'string')]\n",
      "size = 193273 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = status.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'string')]\n",
      "size = 2043 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = driver.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'string'), ('_c2', 'string'), ('_c3', 'string'), ('_c4', 'string'), ('_c5', 'string'), ('_c6', 'string'), ('_c7', 'string'), ('_c8', 'string')]\n",
      "size = 92286 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = seasons.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'string')]\n",
      "size = 4158 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = driver_standings.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'double'), ('_c4', 'int'), ('_c5', 'string'), ('_c6', 'int')]\n",
      "size = 806998 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = qualifying.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'int'), ('_c4', 'int'), ('_c5', 'int'), ('_c6', 'string'), ('_c7', 'string'), ('_c8', 'string')]\n",
      "size = 333110 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = constructor_standings.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'double'), ('_c4', 'int'), ('_c5', 'string'), ('_c6', 'int')]\n",
      "size = 282442 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = circuits.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'string'), ('_c2', 'string'), ('_c3', 'string'), ('_c4', 'string'), ('_c5', 'double'), ('_c6', 'double'), ('_c7', 'string'), ('_c8', 'string')]\n",
      "size = 9406 Bytes\n",
      "\n",
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = results.csv\n",
      "content  = [('_c0', 'int'), ('_c1', 'int'), ('_c2', 'int'), ('_c3', 'int'), ('_c4', 'string'), ('_c5', 'int'), ('_c6', 'string'), ('_c7', 'string'), ('_c8', 'int'), ('_c9', 'double'), ('_c10', 'int'), ('_c11', 'string'), ('_c12', 'string'), ('_c13', 'string'), ('_c14', 'string'), ('_c15', 'string'), ('_c16', 'string'), ('_c17', 'int')]\n",
      "size = 1507588 Bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of items <br />\n",
    "# Get Items' content, name and size <br />\n",
    "# Create a list of item objects\n",
    "\n",
    "import os \n",
    "from pyspark import SparkContext\n",
    "\n",
    "## ITEM objects ###\n",
    "itemList = []\n",
    "index = 0\n",
    "\n",
    "# Ask to introduce schema info if known, else infere schema\n",
    "\n",
    "for f in listFilePath:  \n",
    "    fullPath = tempPath + dataFolder + f\n",
    "    df = sqlContext.read.format('com.databricks.spark.csv').options(header='false', inferschema='true').load(fullPath) # note: custom schema should be defined in deduction phase (later)\n",
    "    content = df.dtypes # list N-tuple <attribute, data type>\n",
    "    size = os.path.getsize(fullPath) # get file size in Bytes\n",
    "    ## Instance\n",
    "    itemList.append(Item(url, f, content, size)) # _id, name, content, size\n",
    "    itemList[index].printInfo()\n",
    "    print() # Add a blank space between instances\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create release objects and append them in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "releaseNum  = 1\n",
      "publicationDate  = Sun, 02 Sep 2018 18:08:37 GMT\n",
      "List of items = [<__main__.Item object at 0x7f362c3b9f98>, <__main__.Item object at 0x7f362c3b9048>, <__main__.Item object at 0x7f362c3b9630>, <__main__.Item object at 0x7f362c3be080>, <__main__.Item object at 0x7f362c3bee48>, <__main__.Item object at 0x7f362c3b51d0>, <__main__.Item object at 0x7f362c3b5b00>, <__main__.Item object at 0x7f362c396f98>, <__main__.Item object at 0x7f362c3b1588>, <__main__.Item object at 0x7f362c3b1c88>, <__main__.Item object at 0x7f362c14cb00>, <__main__.Item object at 0x7f362c14c4e0>, <__main__.Item object at 0x7f362c3b5630>]\n",
      "size = 16605039 Bytes\n"
     ]
    }
   ],
   "source": [
    "############# RELEASE ###############################################################################################\n",
    "# We assume that publication date is the same as the one which the origin server believes the resource was last modified\n",
    "conn = urllib.request.urlopen(\"http://ergast.com/downloads/f1db_csv.zip\", timeout=30)\n",
    "last_modified = conn.headers['last-modified']\n",
    "publicationDate = last_modified\n",
    "\n",
    "# Get release size <br />\n",
    "releaseSize = 0\n",
    "for i in itemList:\n",
    "    releaseSize = i.size + releaseSize\n",
    "\n",
    "# Create a list of release objects    \n",
    "releaseList = []\n",
    "                           #_id, releaseNum, publicationDate, itemList, size\n",
    "releaseList.append(Release(url, 1, publicationDate, itemList, releaseSize)) \n",
    "releaseList[0].printInfo()\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data collection object\n",
    "Using release size since both release and collection have the same data <br />\n",
    "Adding parameter manually, consider extracting them programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id  = http://ergast.com/downloads/f1db_csv.zip\n",
      "name  = f1db_csv/\n",
      "provider  = Ergast Developer API\n",
      "licence  = Restricted\n",
      "size = 16605039 Bytes\n",
      "author  = ergast\n",
      "description  = Add API decription\n",
      "list of releases = [<__main__.Release object at 0x7f362c14c358>]\n"
     ]
    }
   ],
   "source": [
    "############# COLLECTION ############################################################################################\n",
    "# Ask for database name, provider, licence, author and description\n",
    "# _id = url maybe change for a hdfs url\n",
    "                                #_id, name, provider, licence, size, author, description, releaseList\n",
    "dataCollection = DataCollection(url, dataFolder, \"Ergast Developer API\", \"Restricted\", releaseSize, \"ergast\", \"description\", releaseList) \n",
    "dataCollection.printInfo()\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
